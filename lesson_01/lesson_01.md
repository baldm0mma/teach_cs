## Lesson 01

### Computational Thinking and Problem Solving
- All computer science is, is the use of compuational thinking to solve problems. Programming is one way to implement computational thinking. It uses human-readable code to communicate with the computer. This is called a "program." The basic structure of a program is this:
  - INPUT -> [black box] -> OUTPUT. The Programmer's job is to write the code that goes in the black box.
- Let's say we are a owner of a grocery store, and we need to count the number of apples we have avaiable for sale. We can simply use our fingers. We can count the apples one by one, and keep track of the count. If we only use our fingers, we are using a unary system, or base-1 counting system. A unary systsem only uses a single symbol to count. Other examples of unary counting are hash marks, or tally marks.
- Computers, of course, don't use a urnary system. They use a binary system, or base-2 counting system. In a binary system, there are only two symbols: 0 and 1.
  - If you have every heard of a bit, this word is short for "binary digit." A bit is the smallest unit of data in a computer. It can only have one of two values: 0 or 1.
  - Now, as humans, most of us use a different system for counting, called the decimal system, or base-10 counting system. In a base-10 system, there are 10 symbols: 0, 1, 2, 3, 4, 5, 6, 7, 8, and 9.
  - There are also, of course, other counting systems, like hexidecimal, or base-16 counting system. In a base-16 system, there are 16 symbols: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, and F. Or a base-60 counting system, called sexagesimal, which is used in timekeeping. Or a base-12 counting system, called duodecimal, which is used also for timekeeping, but also for measurements. Or a base-64 counting system, which is used as a binary-to-text encoding scheme.
- But how do computers speak in binary? Why is that their system?
  - If we want to represent these digits, these symbols, these ideas, we need to do so physically, some how. We use physical representations of binary all the time. Light switches. A light switch can be in one of two positions: on or off. This is a binary system. A light switch is a physical representation of a bit.
  - Inside the computer, there are, metaphorically millions of little light bulbs, or little switches. These switches are called transistors. A transistor is a tiny switch that can be in one of two positions: on or off, 1 or 0, or true or false.
  - But in its most literal form, a transistor is a tiny piece of silicon, a semiconductor, that can be in one of two states: conductive or non-conductive. When a transistor is conductive, it is on, or 1. When a transistor is non-conductive, it is off, or 0.
  - Everything a computer does in based in this binary system.
- But computers don't just count. If everything is 0s and 1s, how does it do other stuff, like send emails, make network requests, or play games?
  - The answer is that computers can do all of these things because they can represent more than just numbers. They can represent text, images, sound, and video. They can represent anything that can be represented as a sequence of 0s and 1s.
  - For example, text can be represented as a sequence of numbers. Each letter can be represented as a number. For example, the letter "A" can be represented as the number 65. The letter "B" can be represented as the number 66. The letter "C" can be represented as the number 67. And so on.
  - This is called ASCII, or the American Standard Code for Information Interchange. ASCII is a character encoding standard that uses numbers to represent text. ASCII is a 7-bit encoding, which means that it uses 7 bits to represent each character. This means that there are 2^7, or 128, possible characters that can be represented in ASCII.
  - But 128 characters isn't enough to represent all of the characters in all of the world's languages. So there are other character encoding standards, like Unicode, that use more bits to represent more characters. Unicode is a 32-bit encoding, which means that it uses up to 32 bits to represent each character. This means that there are 2^32, or 1.1M possible characters that can be represented in Unicode.